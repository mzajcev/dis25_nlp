{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from spellchecker import SpellChecker\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "data = tfds.load('imdb_reviews', split=['train', 'test'])\n",
    "\n",
    "# Convert the data into pandas DataFrame and decode bytes to string\n",
    "train_df = tfds.as_dataframe(data[0])\n",
    "test_df = tfds.as_dataframe(data[1])\n",
    "\n",
    "# Decode bytes to string\n",
    "train_df['text'] = train_df['text'].apply(lambda x: x.decode('utf-8'))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "# Initialize a spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            correction = spell.correction(word)\n",
    "            if correction is not None:  # Check if the correction is not None\n",
    "                corrected_text.append(correction)\n",
    "            else:\n",
    "                corrected_text.append(word)  # If correction is None, append original word\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "\n",
    "# Correct spelling\n",
    "train_df['text'] = train_df['text']\n",
    "test_df['text'] = test_df['text']\n",
    "\n",
    "# Preprocess the data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Create a classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Suppose you have 50 new samples for testing, which are stored in a CSV file \"test_samples.csv\"\n",
    "# We'll read the file into a DataFrame and preprocess it in the same way as the training data\n",
    "\n",
    "with open('test_data.csv', 'r') as f:\n",
    "    test_data = f.readlines()\n",
    "\n",
    "test_data = [line.strip('\\n') for line in test_data]\n",
    "test_samples_df = pd.DataFrame(test_data, columns=['text'])\n",
    "\n",
    "# Apply correct spelling to 'text' column of DataFrame\n",
    "test_samples_df['text'] = test_samples_df['text'].apply(correct_spelling)\n",
    "\n",
    "X_test_samples = vectorizer.transform(test_samples_df['text'])\n",
    "\n",
    "# Use the trained classifier to make predictions on your test samples\n",
    "predictions = clf.predict(X_test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54        30\n",
      "           1       0.43      0.60      0.50        20\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.53      0.53      0.52        50\n",
      "weighted avg       0.55      0.52      0.52        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train[:50], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier: Logistic\n",
    "# Spellchecker: 50 Testdaten\n",
    "# Stopwords (English / Vectorizer)\n",
    "#              precision    recall  f1-score   support\n",
    "#\n",
    "#           0       0.64      0.47      0.54        30\n",
    "#           1       0.43      0.60      0.50        20\n",
    "#\n",
    "#    accuracy                           0.52        50\n",
    "#   macro avg       0.53      0.53      0.52        50\n",
    "# weighted avg       0.55      0.52      0.52        50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
