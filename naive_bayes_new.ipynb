{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import tensorflow_datasets as tfds\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb reviews dataset\n",
    "data = tfds.load('imdb_reviews', split={'train': 'train', 'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into pandas DataFrame and decode bytes to string\n",
    "train_df = tfds.as_dataframe(data['train'])\n",
    "test_df = tfds.as_dataframe(data['test'])\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x: x.decode('utf-8'))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "train_df['label'] = train_df['label'].replace({0: 'negative', 1: 'positive'})\n",
    "test_df['label'] = test_df['label'].replace({0: 'negative', 1: 'positive'})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, train_df['label'], test_size=0.2, random_state=42, stratify=train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for the sentiment labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2) (20000,)\n",
      "(5000, 2) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spellchecker\n",
    "# spell = SpellChecker()\n",
    "# #Lemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# def transformations(dataframe):\n",
    "#     #HTML Tags removal\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: re.sub('<.*?>','',words)) \n",
    "    \n",
    "#     #Word Tokenization\n",
    "#     dataframe['text'] = dataframe['text'].apply(word_tokenize)\n",
    "    \n",
    "#     #Lower case conversion\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [x.lower() for x in words])\n",
    "    \n",
    "#     #Punctuation removal\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if not x in punctuation])\n",
    "    \n",
    "#     #Number removal\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if not x.isdigit()])\n",
    "    \n",
    "#     # Spellchecker\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [spell.correction(x) for x in words])\n",
    "\n",
    "#     #Stopword removal\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if x not in stopwords.words('english')])\n",
    "    \n",
    "#     # # Frequent word removal\n",
    "#     #temp = dataframe['text'].apply(lambda words: \" \".join(words))\n",
    "#     #freq = pd.Series(temp).value_counts()[:10]\n",
    "#     #dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if x not in freq.keys()])\n",
    "    \n",
    "#     #Lemmatization\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: [lemmatizer.lemmatize(x) for x in words])\n",
    "    \n",
    "#     # Join\n",
    "#     dataframe['text'] = dataframe['text'].apply(lambda words: \" \".join(words))\n",
    "    \n",
    "#     return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def spell_checker(text):\n",
    "    return [spell.correction(word) for word in text]\n",
    "\n",
    "def lemmatize_words(words):\n",
    "    return [lemmatizer.lemmatize(x) if lemmatizer.lemmatize(x) else x for x in words]\n",
    "\n",
    "def transformations(dataframe):\n",
    "    # HTML Tags removal\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: re.sub('<.*?>', '', ' '.join(filter(None, words)))) \n",
    "    \n",
    "    # Word Tokenization\n",
    "    dataframe['text'] = dataframe['text'].apply(word_tokenize)\n",
    "    \n",
    "    # Lower case conversion\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: [x.lower() for x in words])\n",
    "    \n",
    "    # Punctuation removal\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if not x in punctuation])\n",
    "    \n",
    "    # Number removal\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if not x.isdigit()])\n",
    "    \n",
    "    # Spellchecker\n",
    "    dataframe['text'] = dataframe['text'].apply(spell_checker)\n",
    "\n",
    "    # Stopword removal\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: [x for x in words if x not in stopwords.words('english')])\n",
    "    \n",
    "    # Lemmatization\n",
    "    dataframe['text'] = dataframe['text'].apply(lemmatize_words)\n",
    "\n",
    "    # Join again\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda words: \" \".join(words))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:10]\n",
    "clean_data_train_data = transformations(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>positive</td>\n",
       "      <td>latest film spanish director gust study child ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>negative</td>\n",
       "      <td>others mentioned movie similar fly version les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24558</th>\n",
       "      <td>positive</td>\n",
       "      <td>idea describe movie also would love provide ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>positive</td>\n",
       "      <td>ah loved movie think made laugh loud dozen tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16059</th>\n",
       "      <td>positive</td>\n",
       "      <td>brilliant movie drawing amazing bad ended begu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>positive</td>\n",
       "      <td>i've seen ton action one right top genre actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24251</th>\n",
       "      <td>negative</td>\n",
       "      <td>show clever basically boil original humor writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15600</th>\n",
       "      <td>positive</td>\n",
       "      <td>christopher lloyd funny really believable al h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10668</th>\n",
       "      <td>positive</td>\n",
       "      <td>movie absolutely expecting highbrow intellectu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>positive</td>\n",
       "      <td>movie jackie best still cant get enough watchi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "15072  positive  latest film spanish director gust study child ...\n",
       "9987   negative  others mentioned movie similar fly version les...\n",
       "24558  positive  idea describe movie also would love provide ot...\n",
       "2571   positive  ah loved movie think made laugh loud dozen tim...\n",
       "16059  positive  brilliant movie drawing amazing bad ended begu...\n",
       "7301   positive  i've seen ton action one right top genre actio...\n",
       "24251  negative  show clever basically boil original humor writ...\n",
       "15600  positive  christopher lloyd funny really believable al h...\n",
       "10668  positive  movie absolutely expecting highbrow intellectu...\n",
       "14596  positive  movie jackie best still cant get enough watchi..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
